{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Load Train and test data\nX_train = pd.read_csv('/kaggle/input/titanic/train.csv')\nX_test = pd.read_csv('/kaggle/input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get a brief about the data types\nX_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The percentage of null values in the dataset\nprint(X_train.isnull().sum()/X_train.shape[0])\nprint('*'*25)\nprint(X_test.isnull().sum()/X_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#More than 70 % of data is missing in cabin column . We can drop it.\nX_train.drop(['Cabin'],axis=1,inplace=True)\nX_test.drop(['Cabin'],axis=1,inplace=True)\n\n#Impute the mising values in Age and Fare\nX_train['Age'].fillna(X_train['Age'].median(),inplace=True)\nX_test['Age'].fillna(X_test['Age'].median(),inplace=True)\nX_test['Fare'].fillna(X_test['Fare'].mean(),inplace=True)\n#There are only three missing values in Embarked column, so we can drop it\nX_train = X_train.dropna(axis=0, subset=['Embarked'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop the passengerid as it is just a unique identifier and also drop dependant variable\nX = X_train.drop(['Survived','PassengerId'],axis=1)\ny= X_train['Survived']\n\n#Split the into train and validation and use test data for predictions\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find the indices for categorical columns\ncategorical_features_indices = np.where(X_train.dtypes == np.object)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing library and building model. \n#Here we are using CatBoostRegressor as our model. CatBoostRegressor will handle categorical data\n#I have fine tuned the hyperparameters -depth,iterations,learning_rate for this dataset\nfrom catboost import CatBoostClassifier\nmodel=CatBoostClassifier(iterations=34, depth=15, learning_rate=0.2, loss_function='Logloss')\nmodel.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_val, y_val),plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Catboosregressor gives the probabiites rather than the actual value.\ny_pred_train = pd.Series(model.predict(X)) \nX_test_1 = X_test.drop('PassengerId',axis=1) \ny_pred = pd.Series(model.predict(X_test_1)) \ny_pred_val = pd.Series(model.predict(X_val))\ndef step(x): #Step function\n    if x> 0.5:\n        return 1\n    else:\n        return 0\n\n#Apply step function to convert the predictions to 0 or 1\ny_pred_train = y_pred_train.apply(step)\ny_pred = y_pred.apply(step)\ny_pred_val = y_pred_val.apply(step)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create confusion matrix and compute the accuracy score of predictions\nfrom sklearn.metrics import confusion_matrix,accuracy_score\ncm_train = confusion_matrix(y,y_pred_train)\nac = accuracy_score(y,y_pred_train)\nprint(\"Confucion matirx on train data\\n\",cm_train)\nprint(\"Accuracy score on train data: \",ac)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy score on validation data: \",accuracy_score(y_val,y_pred_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prepare for submission\nX_test_predict = X_test.drop('PassengerId',axis=1) #drop the passenger id as we did't fit the model with passengerid column\npredict_to_submit = pd.Series(model.predict(X_test_predict)) #make predcitions and convert them into padnaseries so that we can apply step function on the pandas series data\npredict_to_submit = predict_to_submit.apply(step) #Apply step function to convert the predictions to 0 or 1\nmy_submission = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived': predict_to_submit}) #Make the DF for submision data\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False) #Save the submission file.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}